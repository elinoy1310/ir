📘 שלבי העבודה בפרויקט – קורס איחזור מידע
🟦 שלב 1 – הורדת קבצי ה־XML

שם הסקריפט: download_debates.py

🎯 מטרה

להוריד את כל קבצי ה־XML של פרוטוקולי הפרלמנט הבריטי החל מהקובץ debates2023-06-28d.xml ועד הסוף (כ־935 קבצים) לצורך עיבוד בהמשך.

⚙️ מה נעשה

נכתב סקריפט בפייתון המשתמש בספריות requests ו־tqdm להורדה אוטומטית של הקבצים.

הסקריפט:

שואב את רשימת הקבצים מהאתר.

מסנן לפי שם הקובץ המבוקש.

מוריד כל קובץ לתיקייה debates_xml תוך הצגת התקדמות.

מדלג על קבצים שכבר הורדו.

💡 הסיבה לבחירה

שיטה פשוטה, אמינה וחסכונית — מאפשרת הורדה אוטומטית מלאה ללא שימוש ידני בדפדפן, עם הגנות בפני ניתוקים או שגיאות רשת.

📈 תוצאות

כל הקבצים ירדו בהצלחה לתיקייה מקומית.

שמות הקבצים נשמרו במדויק.

שגיאות אפשריות:

ניתוק רשת או Timeout → נפתר באמצעות מנגנון Retry.

קובץ פגום → נבדק לפי גודל, והסקריפט מדלג ומנסה שוב.

🟩 שלב 2 – ניקוי קבצי ה־XML ובדיקת קבצים ריקים

שמות הסקריפטים:

clean_xml_folder.py – ניקוי תגיות XML.

check_empty_files.py – בדיקת קבצים ריקים.

🎯 מטרה

להמיר את קבצי ה־XML לקבצי טקסט נקיים המכילים רק את תוכן הדיבור (ללא תגיות HTML או XML), ולוודא שכל הקבצים שנוצרו אכן תקינים ולא ריקים.

⚙️ מה בוצע
1️⃣ ניקוי תגיות ה־XML

שימוש בספרייה lxml לעיבוד כל קובץ XML.

חילוץ כל הטקסט שבין התגים באמצעות itertext().

הסרת רווחים ותווים מיותרים.

שמירת קובצי טקסט חדשים (.txt) בתיקייה clean_text בשם זהה למקור.

טיפול בשגיאות פרסינג באמצעות קובץ לוג error_log.txt.

2️⃣ בדיקת קבצים ריקים

מעבר על כל קובצי הטקסט בתיקייה.

בדיקה אם גודל הקובץ הוא 0 או שהתוכן קצר מ־10 תווים.

הדפסת רשימת כל הקבצים הריקים או כמעט ריקים.

💡 הסיבה לבחירה

lxml מאפשרת ניתוח מדויק של מבנה XML גם בקבצים מורכבים.

בדיקת קבצים ריקים מבטיחה שקבצים ריקים לא ישפיעו על תוצאות ניתוח המידע בהמשך (TF-IDF, Embeddings).

📈 תוצאות

נוצרו קבצי טקסט נקיים בתיקייה clean_text.

נוצר קובץ לוג לשגיאות פרסינג.

הופקה רשימת קבצים ריקים שנמצאו:

נמצאו 13 קבצים ריקים או כמעט ריקים:
- debates2023-11-14b.txt
- debates2023-12-13b.txt
- debates2023-12-18b.txt
- debates2024-02-06c.txt
- debates2024-05-23b.txt
- debates2024-05-24b.txt
- debates2024-07-17e.txt
- debates2024-12-12b.txt
- debates2025-01-17c.txt
- debates2025-01-22a.txt
- debates2025-03-20a.txt
- debates2025-07-21c.txt
- debates2025-07-22c.txt

🟨 שלב 3 – ניקוי טקסט והפרדת מילים מסימני פיסוק

שם הסקריפט: tokenize_clean_text.py

🎯 מטרה

להבטיח שכל מילה תעמוד בפני עצמה ללא סימני פיסוק צמודים, כך שהמערכת תוכל לבצע חישובי TF-IDF ו־Embeddings בצורה מדויקת.

⚙️ מה בוצע

נכתב סקריפט המשתמש ב־Regex לטוקניזציה מתקדמת.

מזהה מילים בעברית ובאנגלית, כולל תווים מיוחדים כמו גרשיים עבריים (צה"ל, צה״ל).

מפריד סימני פיסוק (. , : ; ? ! ( ) [ ] " - …) כך שכל אחד נשמר כטוקן עצמאי.

שומר את התוצאה בתיקייה tokens תוך שמירה על שמות הקבצים המקוריים.

מטפל בשגיאות קריאה וכתיבה, ומדלג על קבצים בעייתיים.

💡 הסיבה לשיטה

גישה זו שומרת על מבנה המשפט אך מאפשרת ניתוח מילים נפרדות לצורך ניתוח לשוני מדויק, הפחתת רעש ושיפור איכות האינדקס (למשל: ממשלה. לא תיחשב שונה מ־ממשלה).

📈 תוצאות

נוצרו גרסאות “מטוקננות” של כל הקבצים בתיקייה tokens.

כל מילה וסימן פיסוק מופרדים ברווח אחד בלבד.

הנתונים מוכנים כעת לשלב הבא – הסרת stopwords ולממטיזציה (lemmatization).

בשלב יצירת גרסאות הלמות בחרנו להשתמש בכלי spaCy, ובפרט במודל en_core_web_sm.
הספרייה spaCy נבחרה בזכות הדיוק הגבוה שלה בלמטיזציה מבוססת הקשר תחבירי (POS tagging) ובזכות ביצועיה הטובים בעיבוד טקסטים ארוכים באנגלית.
הכלי יודע לזהות את הצורה הבסיסית (lemma) של כל מילה בהתאם להקשרה במשפט, מה שמפחית וריאציות מיותרות ומאפשר ייצוגים עקביים יותר בשלבים הבאים של חישוב TF-IDF ו־Word2Vec.
התהליך בוצע על כל קובצי הטקסט הנקיים מתגי XML, כאשר לכל קובץ נוצר קובץ חדש בשם זהה בתיקייה נפרדת lemmatized_text.

🧩 סיכום ביניים – עד שלב 4.1
🎯 מטרה כללית

להכין את הנתונים הגולמיים (פרוטוקולים מהפרלמנט הבריטי) כך שכל מסמך יוצג בצורה מספרית מדויקת — כדי שנוכל בהמשך להשוות, לנתח ולחשב רלוונטיות בין מסמכים.

🔹 מה בוצע בפועל

הורדת הקבצים – הורדנו מאות קבצי XML מהמאגר הרשמי של הפרלמנט הבריטי.

ניקוי התוכן – הסרנו תגיות XML, תווים מיוחדים וסימני פיסוק, והפקנו טקסט נקי.

הפרדת מילים (Tokenization) – דאגנו שכל מילה וסימן פיסוק יעמדו בנפרד.

יצירת למות (Lemmatization) – הפכנו מילים לצורת השורש שלהן (כמו running → run).

בניית מטריצות TF-IDF ו־BM25 (Word-level) –
לכל מסמך יצרנו וקטור מספרי שמראה אילו מילים מופיעות בו וכמה הן חשובות,
תוך שימוש בצמצום מאפיינים (הסרת stopwords ומילים נדירות).

📊 תוצאות

957 מסמכים

29,162 מאפיינים (מילים שונות)

צפיפות מטריצה: כ־7.5% (מטריצה דלילה — רוב הערכים אפסיים)

נשמרו:

TFIDF_Word.npz

BM25_Word.npz

מיפוי מילים (vocabulary.json)

מיפוי שמות קבצים (files.json)

💡 משמעות התוצאה

עכשיו כל מסמך מוכן לשלב הבא —
למדוד חשיבות מילים בצורה מתקדמת יותר (על בסיס למות)
ולעבור למודלים סמנטיים כמו Word2Vec, GloVe ו־SBERT.

תוצאה: (venv) C:\Users\user\Desktop\שנה ד\איחזור מידע\ir>python build_vectors_word.py --input lemmatized_text --outdir vectors_lemm
נקראו 943 מסמכים מ-lemmatized_text
TF-IDF shape: (943, 22993), צפיפות: 0.078101
Counts shape: (943, 22993)

✅ נשמרו קבצים בתיקייה: C:\Users\user\Desktop\שנה ד\איחזור מידע\ir\vectors_lemm
  - TFIDF_Word.npz + vocab + files
  - BM25_Word.npz  + vocab + files



🧩 סיכום – שלב 4.1 (Lemmas)
🎯 מטרה

לבנות מטריצות TF-IDF ו-BM25 על בסיס הלמות (צורות השורש של המילים),
כדי לבדוק האם ייצוג לפי למות מפחית רעש לשוני ומשפר את איכות המידע לעומת ייצוג לפי מילים רגילות.

⚙️ מה בוצע

נקראו 943 מסמכים מתוך התיקייה lemmatized_text.

נוצרו שתי מטריצות:

TF-IDF_Lemm — חישוב חשיבות של כל למָה בכל מסמך.

BM25_Lemm — גרסה משוקללת עם התאמה לאורך המסמך.

הוסרו stop-words באנגלית, ומילים נדירות מדי (פחות מ-5 הופעות).

נשמרו גם מיפויים (vocabulary.json, files.json) כדי לדעת איזו עמודה שייכת לאיזו למָה ואיזו שורה לאיזה קובץ.

📊 תוצאות

מספר מסמכים: 943

מספר למות ייחודיות: 22,993

צפיפות: ‎≈ 0.078 (דלילה מאוד – כמו שצפוי בטקסט טבעי)

תיקיית פלט: vectors_lemm/

TFIDF_Lemm.npz

BM25_Lemm.npz

קבצי מיפוי נלווים (*.json)

💡 תובנה

בהשוואה לגרסת המילים (Word-level), מתקבלת מטריצה קטנה יותר
(פחות מאפיינים – 22.9K לעומת 29.1K), כי צורות שונות של אותה מילה אוחדו.
זה מאשר שהלמטיזציה הפחיתה כפילויות ואחידות את השפה, מה שמייעל את ניתוח הנתונים בהמשך.

התוצאה: 
נקראו 943 מסמכים מ-lemmatized_text TF-IDF shape: (943, 22993), צפיפות: 0.078101 Counts shape: (943, 22993) ✅ נשמרו קבצים בתיקייה: C:\Users\user\Desktop\שנה ד\איחזור מידע\ir\vectors_lemm - TFIDF_Word.npz + vocab + files - BM25_Word.npz + vocab + files


🧩 סיכום – שלב 4.2 (Word2Vec)
🎯 מטרה

לייצר ייצוג סמנטי לכל מסמך בעזרת Word2Vec, כך שמילים בעלות משמעות דומה יקבלו ייצוגים קרובים במרחב המספרי.

⚙️ מה בוצע

אימון שני מודלי Word2Vec – אחד על מילים רגילות (tokens) ואחד על למות (lemmas).

לכל מסמך חושב וקטור ממוצע של מילותיו (ממד 300).

נבנו שתי גרסאות לכל רמה:

basic – ללא פיסוק, מספרים ותווים מיוחדים.

nostop – בנוסף גם ללא stop-words.

📊 תוצאות

Word-level: ‎957 מסמכים × 300 ממדים.

Lemma-level: ‎943 מסמכים × 300 ממדים.

נשמרו בקבצים בתיקייה embeddings_w2v/:

W2V_Word_basic.npy, W2V_Word_nostop.npy

W2V_Lemm_basic.npy, W2V_Lemm_nostop.npy

ו־w2v_model_word.model, w2v_model_lemm.model




### תיעוד לשלב חישוב ה-**Information Gain** ו-**Chi-Square** על מטריצת TF-IDF

#### מטרת השלב:

בשלב זה, המטרה הייתה למדוד את **החשיבות של כל מאפיין** (מילה או למה) במטריצות ה-TFIDF שנבנו קודם לכן, באמצעות שני מדדים:

1. **Information Gain (IG)** – מדד שמחשב את השינוי במידע כאשר נעשה חלוקה של הקבוצות (במקרה שלנו, המסמכים).
2. **Chi-Square** – מדד לבחינת הקשר בין כל מאפיין (מילה) לבין הקטגוריות של המסמכים (למשל, שם הקובץ, שמייצג קטגוריה או תווית).

#### **Information Gain (IG):**

**מה עשינו:**

1. השתמשנו במטריצת ה-TFIDF שנבנתה קודם על ידי `TfidfVectorizer` כדי לחשב את ה-Information Gain של כל מילה במסמכים.
2. ה-Information Gain משמש למדוד את "ההבחנה" שמספק כל פיצ'ר (מילה) בכל הקשר של הקטגוריות (למשל, השמות של הקבצים).
3. ככל ש-IG גבוה יותר, המשמעות היא שהמילה תורמת יותר להבחנה בין הקטגוריות.
4. השתמשנו ב-`mutual_info_classif` מתוך ספריית `sklearn` כדי לחשב את ה-IG עבור כל מילה במטריצה.

**כיצד חישבנו:**

* ייבאנו את המטריצה עם הפיצ'רים המילוליים (`load_npz`) ואת השמות של הקבצים.
* המרת השמות (של הקבצים) לקטגוריות באמצעות `LabelEncoder`.
* שימוש ב-`mutual_info_classif` לחישוב ה-Information Gain עבור כל פיצ'ר (מילה).

**הסבר על **Information Gain:**

* ה-IG נמדד על פי השפעת כל פיצ'ר (מילה) על הסיווג של הקטגוריות. מדד זה מתאר את הערך של כל פיצ'ר בבחינת התרומה שלו להבחנה בין קטגוריות שונות.
* ככל ש-IG גבוה יותר, הפיצ'ר נחשב ליותר משמעותי בזיהוי תבניות בנתונים.

**תוצאות:**

* לאחר החישוב, השווינו את ה-IG עבור כל מילה. מילים עם IG גבוה נחשבו כמילים שמספקות יותר מידע בהבחנה בין הקטגוריות.

#### **Chi-Square:**

**מה עשינו:**

1. לאחר חישוב ה-IG, החלטנו להוסיף גם מדד נוסף שמודד את הקשר בין כל פיצ'ר (מילה) לבין הקטגוריות של המסמכים. המדד שנבחר היה **Chi-Square statistic**.
2. מדד ה-Chi-Square בודק האם יש קשר בין כל מילה לבין הקטגוריות (שמות הקבצים). מדובר במדד סטטיסטי שמחשב את ההבדל בין ההתפלגות הממשית של המילים לבין ההתפלגות הצפויה אם המילים היו מופיעות באופן אקראי בכל קטגוריה.
3. השתמשנו ב-`chi2` מתוך ספריית `sklearn.feature_selection` לחישוב מדד ה-Chi-Square לכל מילה.

**כיצד חישבנו:**

* ייבאנו את המטריצה (`load_npz`) ואת שמות הקבצים.
* השתמשנו ב-`chi2` כדי לחשב את ה-**Chi-Square** בין כל פיצ'ר (מילה) לבין הקטגוריות (תוויות המסמכים).
* לאחר מכן יצרנו **DataFrame** שמכיל את המילים, ערך ה-Chi-Square שלהם ו-P-Value.

**הסבר על **Chi-Square:**

* ה-**Chi-Square statistic** משמש לבדיקת אי-תלות בין משתנים. במקרה שלנו, הוא בודק את הקשר בין כל מילה לבין הקטגוריות של המסמכים.
* ערך **Chi-Square** גבוה מצביע על קשר חזק בין המילה לבין קטגוריה מסוימת, בעוד שערך נמוך מצביע על חוסר קשר בין המילה לבין הקטגוריה.
* ערך ה-**P-Value** מציין את המובהקות הסטטיסטית של התוצאה: P-Value נמוך מציין שהתוצאה מובהקת סטטיסטית.

**תוצאות:**

* יצאנו עם רשימה של מילים, ערכי **Chi-Square** ו-P-Value.
* מילים עם **Chi-Square** גבוה ו-P-Value נמוך מצביעות על קשר חזק ומובהק עם הקטגוריה.

### **הסיבה לבחירת מדד ה-**Chi-Square:

בחרנו במדד **Chi-Square** מכיוון שהוא מאוד פופולרי ויעיל במדידות סטטיסטיות, במיוחד כשאנחנו עוסקים במדידה של קשר בין משתנים קטגוריים (במקרה שלנו, מילים וקטגוריות). ה-Chi-Square הוא כלי מצוין לבחינת מובהקות סטטיסטית של הפיצ'רים (המילים) במטריצה והאם הם תורמים להבחנה בין הקטגוריות. יתר על כן, ה-Chi-Square הוא מדד פשוט ונפוץ, כך שניתן לפרש את התוצאות בקלות.

#### **סיכום**:

* **Information Gain** (IG) נמדד בעזרת `mutual_info_classif` ומודד את התרומה של כל מילה להבחנה בין הקטגוריות.
* **Chi-Square statistic** נמדד בעזרת `chi2` והוא מספק מדד מובהקות סטטיסטית לקשר בין המילים לבין הקטגוריות.
* כל אחד מהמדדים משלים את השני: IG מודד את התרומה של המילה להבחנה, בעוד ש-**Chi-Square** מודד את העוצמה של הקשר בין המילה והקטגוריות.

באמצעות שני המדדים הללו, ניתן לקבל תמונה טובה על אילו מילים הן החשובות ביותר עבור כל קטגוריה ולבצע סינון של הפיצ'רים במטריצות ה-TFIDF.
